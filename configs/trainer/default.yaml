_target_: pytorch_lightning.Trainer

default_root_dir: ${paths.output_dir}

min_epochs: 100  # prevents early stopping
max_epochs: 1000

strategy: ddp_find_unused_parameters_false

accelerator: gpu
devices: 1
num_nodes: 1
sync_batchnorm: True

# mixed precision for extra speed-up
# precision: 16

# perform a validation loop every N training epochs
check_val_every_n_epoch: 1

# gradient accumulation to simulate larger-than-GPU-memory batch sizes
accumulate_grad_batches: 1

# set True to ensure deterministic results
# makes training slower but gives more reproducibility than just setting seeds
deterministic: False
